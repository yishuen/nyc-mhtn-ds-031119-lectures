{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Off\n",
    "\n",
    "Sometimes when trying to classify problems like fraud detection, the dataset will have a lot of non-fraud cases and realtively few fraud cases.  How could a class imbalance cause a problem with your model. \n",
    "\n",
    "*use the term bias in your answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Practicum with Class Imbalance\n",
    "\n",
    "Agenda:\n",
    "- Review class imbalance\n",
    "- Review code for different ways to handle class imbalance\n",
    "- Review code for Random Forest with gridsearch\n",
    "- Practice both class imbalance and Random Forest on credit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data and split data to be used in the models\n",
    "titanic = pd.read_csv('cleaned_titanic.csv', index_col='PassengerId')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matrix of features\n",
    "X = titanic.drop('Survived', axis = 1) # grabs everything else but 'Survived'\n",
    "\n",
    "# Create target variable\n",
    "y = titanic['Survived'] # y is the column we're trying to predict\n",
    "\n",
    "# Create a list of the features being used in the \n",
    "feature_cols = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline  \n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize = (10,5))\n",
    "sns.countplot(y, alpha =.80, palette= ['grey','lightgreen'])\n",
    "plt.title('Survivors vs Non-Survivors')\n",
    "plt.ylabel('# Passengers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a Dummy Classifier for Baseline Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.6412556053811659\n",
      "Test F1 score:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/swilson5/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=23)\n",
    "\n",
    "# DummyClassifier to predict only target 0\n",
    "dummy = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "dummy_pred = dummy.predict(X_test)\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "print('Test Accuracy score: ', accuracy_score(y_test, dummy_pred))\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "print('Test F1 score: ', f1_score(y_test, dummy_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a classification Model with class imbalance\n",
    "\n",
    "Below you will see there is code for both a Decision Tree classifier and Logistic classifier. Currently the decision tree code is commented out. There is no reason for both of these other than I was comparing the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.820627802690583\n",
      "Test F1 score:  0.7402597402597403\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# dt_clf = DecisionTreeClassifier(max_depth=5)\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# dt_clf.fit(X_train, y_train)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_test = dt_clf.predict(X_test)\n",
    "y_pred_test = lr_clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "print('Test Accuracy score: ', accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "print('Test F1 score: ', f1_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping data for handling class imbalances\n",
    "\n",
    "We are goign to change the training dataset to which we fit our model, so we want to bring our training data back together before we make those changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate our training data back together\n",
    "training  = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate minority and majority classes\n",
    "deceased = training[training.Survived==0]\n",
    "survived = training[training.Survived==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceased count: 406\n",
      "survived count: 260\n"
     ]
    }
   ],
   "source": [
    "print('deceased count: '+ str(len(deceased)))\n",
    "print('survived count: '+ str(len(survived)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/resampling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# upsample minority\n",
    "survived_upsampled = resample(survived,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(deceased), # match number in majority class\n",
    "                          random_state=23) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([deceased, survived_upsampled])\n",
    "\n",
    "# check new class counts\n",
    "upsampled.Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying logistic regression again with the balanced dataset\n",
    "y_train = upsampled.Survived\n",
    "X_train = upsampled.drop('Survived', axis=1)\n",
    "\n",
    "\n",
    "# upsampled_dt = DecisionTreeClassifier(max_depth=5)\n",
    "upsampled_lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "\n",
    "# upsampled_dt.fit(X_train, y_train)\n",
    "upsampled_lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# upsampled_pred = upsampled_dt.predict(X_test)\n",
    "upsampled_pred = upsampled_lr.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "print('Test Accuracy score: ', accuracy_score(y_test, upsampled_pred))\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "print('Test F1 score: ', f1_score(y_test, upsampled_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# downsample majority\n",
    "survived_downsampled = resample(deceased,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(survived), # match minority n\n",
    "                                random_state = 23) # reproducible results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    260\n",
       "0    260\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([survived_downsampled, survived])\n",
    "\n",
    "# checking counts\n",
    "downsampled.Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.7937219730941704\n",
      "Test F1 score:  0.7228915662650603\n"
     ]
    }
   ],
   "source": [
    "# trying logistic regression again with the balanced dataset\n",
    "y_train = downsampled.Survived\n",
    "X_train = downsampled.drop('Survived', axis=1)\n",
    "\n",
    "\n",
    "# downsampled_dt = DecisionTreeClassifier(max_depth=5)\n",
    "downsampled_lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "\n",
    "# downsampled_dt.fit(X_train, y_train)\n",
    "downsampled_lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# downsampled_pred = upsampled_dt.predict(X_test)\n",
    "downsampled_pred = downsampled_lr.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "print('Test Accuracy score: ', accuracy_score(y_test, downsampled_pred))\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "print('Test F1 score: ', f1_score(y_test, downsampled_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-sampling: SMOTE\n",
    "\n",
    "SMOTE (Synthetic Minority Oversampling Technique) consists of synthesizing elements for the minority class, based on those that already exist. It works randomly picking a point from the minority class and computing the k-nearest neighbors for this point. The synthetic points are added between the chosen point and its neighbors.\n",
    "\n",
    "![alt text](images/smote.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=23)\n",
    "\n",
    "sm = SMOTE(random_state=23, ratio=1.0)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.7847533632286996\n",
      "Test F1 score:  0.68\n"
     ]
    }
   ],
   "source": [
    "# smote_dt = DecisionTreeClassifier(max_depth=5)\n",
    "smote_lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "\n",
    "# smote_dt.fit(X_train, y_train)\n",
    "smote_lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# smote_pred = smote_dt.predict(X_test)\n",
    "smote_pred = smote_lr.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "print('Test Accuracy score: ', accuracy_score(y_test, smote_pred))\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "print('Test F1 score: ', f1_score(y_test, smote_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state = 23, n_estimators=100, max_depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=23, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=23, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.7982062780269058\n",
      "Test F1 score:  0.6853146853146853\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "print('Test Accuracy score: ', accuracy_score(y_test, rfc_pred))\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "print('Test F1 score: ', f1_score(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [200,300,400],\n",
    "    'max_features': [0.25, 0.33, 0.5 ],\n",
    "    'max_depth' : [5,6,7,8,9],\n",
    "    'min_samples_leaf': [0.03,0.04,0.05,0.06]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/swilson5/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=23, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [200, 300, 400], 'max_features': [0.25, 0.33, 0.5], 'max_depth': [5, 6, 7, 8, 9], 'min_samples_leaf': [0.03, 0.04, 0.05, 0.06]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5,n_jobs=-1)\n",
    "CV_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'max_features': 0.5,\n",
       " 'min_samples_leaf': 0.03,\n",
       " 'n_estimators': 300}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.7982062780269058\n",
      "Test F1 score:  0.6808510638297872\n"
     ]
    }
   ],
   "source": [
    "rfc_pred = CV_rfc.best_estimator_.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "print('Test Accuracy score: ', accuracy_score(y_test, rfc_pred))\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "print('Test F1 score: ', f1_score(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
